{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-rU1QsV0fHc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mS5h4ITD_5r"
      },
      "outputs": [],
      "source": [
        "def SGD_regression(epochs, B, time_steps, train_images, train_labels, step_size = 0.01):\n",
        "  \"\"\"\n",
        "  Stochastic Gradient Descent (SGD) for logistic regression.\n",
        "\n",
        "  Parameters:\n",
        "  - epochs (int): Number of training epochs.\n",
        "  - B (int): Batch size for each iteration.\n",
        "  - time_steps (int): Number of time steps to record for timing.\n",
        "  - train_images (numpy.ndarray): Input features for training.\n",
        "  - train_labels (numpy.ndarray): Output labels for training.\n",
        "  - step_size (float, optional): Learning rate for SGD. Default is 0.01.\n",
        "\n",
        "  Returns:\n",
        "  - weights (numpy.ndarray): Learned weights after training.\n",
        "  - loss (numpy.ndarray): Array of losses at each epoch.\n",
        "  - times (list): List of time passed for each time step.\n",
        "  \"\"\"\n",
        "  #calculating output by logistic regression\n",
        "  def calculate_output(x, w):\n",
        "    exponent = np.clip(-x @ w, -700, 700)  # Clip to prevent overflow/underflow\n",
        "    return 1 / (1 + np.exp(exponent))\n",
        "\n",
        "  #calculate loss\n",
        "  def calculate_loss(x, w, y):\n",
        "    y_hat = calculate_output(x, w)\n",
        "\n",
        "    epsilon = 1e-15\n",
        "    y_hat = np.clip(y_hat, epsilon, 1 - epsilon)\n",
        "    return -1/len(y_hat) * np.sum(y.T @ np.log(y_hat) + (1-y).T @ np.log(1 - y_hat))\n",
        "\n",
        "  #initialize start time for timing\n",
        "  start = time.time()\n",
        "  times = [0]\n",
        "\n",
        "  weights = np.zeros((train_images.shape[1], 1))\n",
        "  N = train_images.shape[0]\n",
        "\n",
        "  loss = np.zeros((epochs+1))\n",
        "  loss[0] = calculate_loss(train_images, weights, train_labels)\n",
        "\n",
        "  for i in tqdm(range(epochs)):\n",
        "    k =  N // B\n",
        "    for j in range(k):\n",
        "      #selecting random inputs/output batch\n",
        "      batch = np.random.choice(range(N),B,replace=False)\n",
        "      batch_input = train_images[batch]\n",
        "      batch_output = train_labels[batch]\n",
        "      #calculating predictions for this batch\n",
        "      y_hat = calculate_output(batch_input, weights)\n",
        "\n",
        "      #calculate gradient for weights\n",
        "      gradient = (batch_input.T @ (y_hat - batch_output[:,np.newaxis]))\n",
        "\n",
        "      #update weights\n",
        "      weights -= step_size * gradient\n",
        "\n",
        "    #calculate new loss\n",
        "    loss[i+1] = calculate_loss(train_images, weights, train_labels)\n",
        "\n",
        "    #calculate time passed for nth pass (n=time_steps)\n",
        "    times.append(time.time() - start)\n",
        "\n",
        "  return weights, loss, times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BRWl11CHwfq"
      },
      "outputs": [],
      "source": [
        "def ADAM_regression(epochs, B, time_steps, train_images, train_labels, learning_rate = 0.001,beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
        "  \"\"\"\n",
        "  ADAM optimization for logistic regression.\n",
        "\n",
        "  Parameters:\n",
        "  - epochs (int): Number of training epochs.\n",
        "  - B (int): Batch size for each iteration.\n",
        "  - time_steps (int): Number of time steps to record for timing.\n",
        "  - train_images (numpy.ndarray): Input features for training.\n",
        "  - train_labels (numpy.ndarray): Output labels for training.\n",
        "  - learning_rate (float, optional): Learning rate for ADAM. Default is 0.001.\n",
        "  - beta1 (float, optional): Exponential decay rate for the first moment estimates. Default is 0.9.\n",
        "  - beta2 (float, optional): Exponential decay rate for the second moment estimates. Default is 0.999.\n",
        "  - epsilon (float, optional): Small constant to avoid division by zero. Default is 1e-8.\n",
        "\n",
        "  Returns:\n",
        "  - weights (numpy.ndarray): Learned weights after training.\n",
        "  - loss (numpy.ndarray): Array of losses at each epoch.\n",
        "  - times (list): List of time passed for each time step.\n",
        "  \"\"\"\n",
        "\n",
        "  #calculating output by logistic regression\n",
        "  def calculate_output(x, w):\n",
        "    return (1 + np.exp(-x @ w))**(-1)\n",
        "\n",
        "  # loss calculations using\n",
        "  def calculate_loss(x, w, y):\n",
        "    y_hat = calculate_output(x, w)\n",
        "\n",
        "    epsilon = 1e-15\n",
        "    y_hat = np.clip(y_hat, epsilon, 1 - epsilon)\n",
        "    return -1/len(y_hat) * np.sum(y.T @ np.log(y_hat) + (1-y).T @ np.log(1 - y_hat))\n",
        "\n",
        "  start = time.time()\n",
        "  times = [0]\n",
        "  weights = np.zeros((train_images.shape[1], 1))\n",
        "  N = train_images.shape[0]\n",
        "  loss = np.zeros((epochs+1))\n",
        "  loss[0] = calculate_loss(train_images, weights, train_labels)\n",
        "\n",
        "  m = 0\n",
        "  v = 0\n",
        "\n",
        "  for i in tqdm(range(epochs)):\n",
        "    k =  N // B\n",
        "    for j in range(k):\n",
        "      #selecting random inputs/output batch\n",
        "      batch = np.random.choice(range(N),B,replace=False)\n",
        "      batch_input = train_images[batch]\n",
        "      batch_output = train_labels[batch]\n",
        "      #calculating predictions for this batch\n",
        "      y_hat = calculate_output(batch_input, weights)\n",
        "\n",
        "\n",
        "      #calculate gradient for weights\n",
        "      gradient = (batch_input.T @ (y_hat - batch_output[:,np.newaxis]))\n",
        "\n",
        "      #update moving averages\n",
        "      m = beta1 * m + (1 - beta1) * gradient\n",
        "      v = beta2 * v + (1 - beta2) * gradient**2\n",
        "\n",
        "      # bias correction\n",
        "      m_hat = m / (1 - beta1**(i * k + j + 1))\n",
        "      v_hat = v / (1 - beta2**(i * k + j + 1))\n",
        "\n",
        "      # update weights using ADAM update rule\n",
        "      weights -= learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n",
        "\n",
        "    loss[i+1] = calculate_loss(train_images, weights, train_labels)\n",
        "\n",
        "    times.append(time.time() - start)\n",
        "\n",
        "  return weights, loss, times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGB0sSci0hEV"
      },
      "outputs": [],
      "source": [
        "#A simple method to sanitize the data gathered by the AI-SGD experiments in R\n",
        "def reorganize_df(df : pd.DataFrame, row_names : list[str], total_passes : int,step_size : int, add_zeros=False):\n",
        "  df = pd.DataFrame(np.array(df).reshape((len(row_names),-1)))\n",
        "  df.index = row_names\n",
        "  if add_zeros:\n",
        "    col_names = list(range(step_size,total_passes+1, step_size))\n",
        "    df.columns = col_names\n",
        "    df[0] = 0\n",
        "    df = df.loc[:,list(range(0, total_passes+1, step_size))]\n",
        "  else:\n",
        "    col_names = list(range(0,total_passes+1, step_size))\n",
        "    df.columns = col_names\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu-wfwqg2UHz"
      },
      "source": [
        "# MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWMTpaZECwua",
        "outputId": "66cf5581-ab6e-4293-c877-11aa2756a8fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, -1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, -1)).astype('float32') / 255\n",
        "\n",
        "# Create binary labels indicating whether the digit is 9 or not\n",
        "train_labels = (train_labels == 9).astype('float32')\n",
        "test_labels = (test_labels == 9).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tWLS0ioQFyH"
      },
      "outputs": [],
      "source": [
        "#initializing experiment parameters\n",
        "epochs = 60\n",
        "time_step = 5\n",
        "B = 1000\n",
        "#running ADAM with the above parameters\n",
        "adam = ADAM_regression(epochs, B, time_step, train_images, train_labels,\n",
        "                       0.001, 0.9,0.99)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0N9epHOcMRbg"
      },
      "outputs": [],
      "source": [
        "#running SGD with the parameters\n",
        "step_size = 0.0001\n",
        "SGD = SGD_regression(epochs, B, time_step, train_images, train_labels, step_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6fApG7ZSfB7"
      },
      "outputs": [],
      "source": [
        "#plotting loss for ADAM and SGD\n",
        "plt.plot(adam[2], adam[1], label=\"ADAM\")\n",
        "plt.plot(adam[2], SGD[1], label=\"SGD\")\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(r\"Loss $(y-\\hat{y})^2$\")\n",
        "plt.legend(fontsize=\"large\")\n",
        "plt.title(\"Logistic Regression on MNIST with SGD and ADAM\")\n",
        "plt.yscale(\"log\")\n",
        "plt.savefig('SGD ADAM loss.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJhtB0vhQJln"
      },
      "outputs": [],
      "source": [
        "#plotting time for SGD and ADAM\n",
        "plt.plot(range(0,epochs+1), adam[2], label=\"ADAM\")\n",
        "plt.plot(range(0,epochs+1), SGD[2], label=\"SGD\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Time (s)\")\n",
        "plt.legend(fontsize=\"large\")\n",
        "plt.title(\"Logistic Regression on MNIST for SGD and ADAM\")\n",
        "#plt.yscale(\"log\")\n",
        "plt.savefig('SGD ADAM time.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5PCt_jEQoHP"
      },
      "outputs": [],
      "source": [
        "ROW_NAMES = [\"SGD\",\"A-SGD\",\"Implicit-SGD\",\"AI-SGD\"]\n",
        "#Data for runs from 0-20 epochs\n",
        "passes_20 = reorganize_df(\n",
        "    pd.read_csv(\"passes_20.csv\", header=None),\n",
        "    ROW_NAMES, 20, 2)\n",
        "errors_20 = reorganize_df(\n",
        "    pd.read_csv(\"error_20.csv\", header=None),\n",
        "    ROW_NAMES, 20, 2)\n",
        "times_20 = reorganize_df(\n",
        "    pd.read_csv(\"times_20.csv\", header=None),\n",
        "    ROW_NAMES, 20, 2, True)\n",
        "\n",
        "#Data for runs from 0-60 epochs\n",
        "passes_60 = reorganize_df(\n",
        "    pd.read_csv(\"passes_60.csv\", header=None),\n",
        "    ROW_NAMES, 60, 2)\n",
        "times_60 = reorganize_df(\n",
        "    pd.read_csv(\"times_60.csv\", header=None),\n",
        "    ROW_NAMES, 60, 2, True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GwVabYzJcCF"
      },
      "outputs": [],
      "source": [
        "#plotting error versus time for the 4  R SGD methods\n",
        "for i in ROW_NAMES:\n",
        "  plt.plot(times_20.loc[i], errors_20.loc[i], label=f\"{i}\")\n",
        "\n",
        "plt.title(\"Time vs Error for AI-SGD and other methods\")\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(fontsize=\"large\")\n",
        "plt.yscale(\"log\")\n",
        "\n",
        "plt.savefig('AI-SGD error.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnQMj397GdUY"
      },
      "outputs": [],
      "source": [
        "#plotting time-elapsed versus epochs for the four methods\n",
        "for i in ROW_NAMES:\n",
        "  plt.plot(passes_60.loc[i], times_60.loc[i], label=f\"{i}\")\n",
        "\n",
        "plt.title(\"Epochs vs Time for AI-SGD and other methods\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Time (s)\")\n",
        "plt.legend(fontsize=\"large\")\n",
        "\n",
        "plt.savefig('AI-SGD time.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyhDUnBUGmY_"
      },
      "outputs": [],
      "source": [
        "#plotting the relative time elapsed for the four R methods and ADAM\n",
        "#each one is normalized relative to their respective SGD method\n",
        "for i in ROW_NAMES:\n",
        "  plt.plot(passes_60.loc[i], np.array(times_60.loc[i])/np.array(times_60.loc[\"SGD\"]), label=f\"{i}\")\n",
        "\n",
        "plt.plot(range(0,epochs+1), np.array(adam[2])/np.array(SGD[2]), label=\"ADAM\")\n",
        "\n",
        "plt.title(\"Epochs vs Time Relative to SGD\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Times slower than SGD\")\n",
        "plt.legend(fontsize=\"large\")\n",
        "\n",
        "plt.savefig('time baseline SGD.png', dpi=300, bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1q0lhKyIVvb"
      },
      "outputs": [],
      "source": [
        "#Plotting Loss vs epochs relative to SGD loss for the 4 R methods and ADAM\n",
        "#each graph is normalized to its respective SGD implementation\n",
        "for i in ROW_NAMES:\n",
        "  plt.plot(passes_20.loc[i], np.array(errors_20.loc[i])/np.array(errors_20.loc[\"SGD\"]), label=f\"{i}\")\n",
        "\n",
        "plt.plot(range(0,21), np.array(adam[1][:21])/np.array(SGD[1][:21]), label=\"ADAM\")\n",
        "\n",
        "plt.title(\"Epochs vs loss relative to SGD loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss proportional to SGD loss\")\n",
        "plt.legend(fontsize=\"large\")\n",
        "\n",
        "plt.savefig('loss baseline SGD.png', dpi=300, bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfjbsDGTuDuE"
      },
      "source": [
        "# CovType dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nirM1FP7MInN"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_covtype\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Fetch the Covertype dataset\n",
        "covtype = fetch_covtype()\n",
        "\n",
        "# Access features and target variable\n",
        "X = covtype.data\n",
        "y = covtype.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train = (X_train - np.min(X_train, axis=0)) / (np.max(X_train, axis=0) - np.min(X_train, axis=0))\n",
        "#X_test = (X_test - np.min(X_test)) / (np.max(X_test) - np.min(X_test))\n",
        "\n",
        "# Create binary labels indicating whether the digit is 2 or not\n",
        "y_train = (y_train == 2).astype('float32')\n",
        "y_test = (y_test == 2).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQYlzRn2uIXV"
      },
      "outputs": [],
      "source": [
        "#initializing experiment parameters\n",
        "epochs = 60\n",
        "time_step = 5\n",
        "B = 5_000\n",
        "step_size = 0.00002"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYdiFiZFujvy"
      },
      "outputs": [],
      "source": [
        "#Run SGD on CovType\n",
        "cSGD = SGD_regression(epochs, B, 1, X_train, y_train, step_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3BOVSsVxaSO"
      },
      "outputs": [],
      "source": [
        "#Run ADAM on CovType\n",
        "cADAM = ADAM_regression(epochs, B, 1, X_train, y_train, 0.05, 0.99, 0.999)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAmPoOduywAm"
      },
      "outputs": [],
      "source": [
        "#plotting loss\n",
        "plt.plot(cADAM[2], cADAM[1], label=\"ADAM\")\n",
        "plt.plot(cSGD[2], cSGD[1], label=\"SGD\")\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(r\"Loss $(y-\\hat{y})^2$\")\n",
        "plt.legend(fontsize=\"large\")\n",
        "plt.title(\"Logistic Regression on CovType with SGD and ADAM\")\n",
        "plt.yscale(\"log\")\n",
        "plt.savefig('Cov - SGD ADAM loss.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsFJT7iv7Cob"
      },
      "outputs": [],
      "source": [
        "#plotting time\n",
        "plt.plot(range(0,epochs+1), cADAM[2], label=\"ADAM\")\n",
        "plt.plot(range(0,epochs+1), cSGD[2], label=\"SGD\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Time (s)\")\n",
        "plt.legend(fontsize=\"large\")\n",
        "plt.title(\"Logistic Regression on CovType for SGD and ADAM\")\n",
        "#plt.yscale(\"log\")\n",
        "plt.savefig('Cov - SGD ADAM time.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTVkehxH7rOz"
      },
      "outputs": [],
      "source": [
        "ROW_NAMES = [\"SGD\",\"A-SGD\",\"Implicit-SGD\",\"AI-SGD\"]\n",
        "#Data for runs from 0-60 epochs\n",
        "c_passes = reorganize_df(\n",
        "    pd.read_csv(\"passes.csv\", header=None),\n",
        "    ROW_NAMES, 60, 2)\n",
        "c_errors = reorganize_df(\n",
        "    pd.read_csv(\"error 4.csv\", header=None, ),\n",
        "    ROW_NAMES, 60, 2)\n",
        "c_times = reorganize_df(\n",
        "    pd.read_csv(\"times 4.csv\", header=None),\n",
        "    ROW_NAMES, 60, 2, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0CXqk58Ce_N"
      },
      "outputs": [],
      "source": [
        "#plotting the relative time elapsed for the four R methods and ADAM\n",
        "#each one is normalized relative to their respective SGD method\n",
        "for i in ROW_NAMES:\n",
        "  plt.plot(c_passes.loc[i], np.array(c_times.loc[i])/np.array(c_times.loc[\"SGD\"]), label=f\"{i}\")\n",
        "\n",
        "plt.plot(range(0,epochs+1), np.array(cADAM[2])/np.array(cSGD[2]), label=\"ADAM\")\n",
        "\n",
        "plt.title(\"Epochs vs Time Relative to SGD\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Times slower than SGD\")\n",
        "plt.legend(fontsize=\"large\")\n",
        "\n",
        "plt.savefig('Cov - time baseline SGD.png', dpi=300, bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmGY930J7ePx"
      },
      "outputs": [],
      "source": [
        "#Plotting Loss vs epochs relative to SGD loss for the 4 R methods and ADAM\n",
        "#each graph is normalized to its respective SGD implementation\n",
        "for i in ROW_NAMES:\n",
        "  plt.plot(c_passes.loc[i], np.array(c_errors.loc[i])/np.array(c_errors.loc[\"SGD\"]), label=f\"{i}\")\n",
        "\n",
        "plt.plot(range(0,epochs+1), np.array(cADAM[1])/np.array(cSGD[1]), label=\"ADAM\")\n",
        "\n",
        "plt.title(\"Epochs vs loss relative to SGD loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss proportional to SGD loss\")\n",
        "plt.legend(fontsize=\"large\")\n",
        "\n",
        "plt.savefig('Cov - loss baseline SGD.png', dpi=300, bbox_inches='tight')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}